---
title: "Aula 2"
author: "Érika S."
date: "21/08/2019"
output:
  pdf_document: default
  html_document: default
---

Alternativamente, para calcular:  

$$\int_{a}^{b}g(t) dt $$

podemos fazer uma mudança nos limites da integral, alterando para 0 a 1. A transformação linear 
$$y = \frac{t-a}{b-a}$$
$$(b-a)y +a = t$$
$$(b-a)dy = dt$$
disto, 

$$\int_{a}^{b}g(t) dt =  \int_{0}^{1}g((b-a)y +a)(b-a) dy $$
$$= (b-a)\int_{0}^{1}g((b-a)y +a)dy$$  

### Exemplo 1

Calcule um estimador de Monte Carlo para

$$\theta = \int_{2}^{4}e^{-x} dx $$

```{r, warning=FALSE, message=FALSE}

set.seed(100)
m = c(100L,1000L,10000L)
a = 2
b = 4


ex1 = function(x){
  y = runif(x)
  d = exp(-((b-a)*y+a))
  cbind(x,(b-a)*mean(d))
}

ex1(100)
ex1(1000)
ex1(10000)
```

### Exemplo 2
**Integração de Monte Carlo para intervalos ilimitados.**   
Use a abordagem de Monte Carlo para estimar a função distribuição da Normal Padrão.   

$$\Phi(x) = \int_{-\infty}^{x}\frac{1}{\sqrt{2\pi}}exp(-\frac{t^2}{2})dt$$  

Primeiro, note que não podemos aplicar o algoritmo diretamente devido os limites de integração ser um intervalo ilimitado. Contudo, podemos dividir este problema em dois casos: $x\geq0$ e x<0, e usar a simetria da densidade da Normal para lidar com o caso x<0. Então o problema é estimar

$$\theta = \int_{0}^{x}e^{-\frac{t²}{2}}dt, x>0$$  

Podemos resolver gerando números da variável U(0,x), mas seria necessário mudar o parâmetro da distribuição uniforme para cada diferente valor da função distribuição. Suponha que preferimos um algoritmo que sempre amostra da U(0,1).  
Note que 
$$\theta = \int_{0}^{x}e^{-\frac{t²}{2}}dt$$

Pode ser escrito mudando os intervalos de integração para 0 a 1, logo

$$y = \frac{t-a}{b-a} =\frac{t}{x} \\ t = yx \\ dt = xdy $$

disto

$$\theta = \int_{0}^{1}exp((-yx)^2/2)xdx$$
Sendo que o x é dado. Portanto, $\theta = E_y[xe^{-(yx)^2/2}]$, sendo que y é distribuido segundo a v.a. U(0,1).
Gerando números aleatórios $y_1,...,y_m$ da U(0,1) e calculando

$$\hat\theta = \frac{1}{m}\sum^m_{i=1}xe^{-(y_ix)^2/2},$$
A média amostral $\hat\theta$ converge para $E(\hat\theta) = \theta$ quando $m \rightarrow \infty$  
- Se x>0, a estimativa de $\Phi(x)$ é $0,5 + \frac{\theta}{\sqrt{2\pi}}$  
- Se x <0 , calcule $\Phi(x) = 1 - \Phi(-x)$ 
- Se x = 0, $\Phi(x) =0,5$

```{r}
set.seed(100)

ex1 = function(x,m){
  y = runif(m)
  x1 = x
  x = ifelse(x<0, -x, x)
  y = runif(m)
  g = x*exp(-(y*x)^2/2)
  Fy = mean(g)/sqrt(2*pi) + 0.5
  fy = ifelse(x1<0, 1 - Fy, Fy)
  fy
}

ex1(0.6,100)
ex1(-0.5,100)
```

